# Hallucination Gap Analysis

**Status**: Scientific Loop Analysis Report
**Date**: 2026-01-27
**Author**: Scientific Loop Agents

---

## Current State

| Metric | Value | Target | Gap |
|--------|-------|--------|-----|
| Hallucination Rate | 9.5% | <5% | 4.5 pp |
| Citation Accuracy | 69.2% | >=90% | 20.8 pp |
| Entailment Rate | 62.1% | >=85% | 22.9 pp |
| Contradiction Rate | 0.0% | 0% | Met |

**Note**: STATUS.md reports 2.3% hallucination rate, but this reflects the live Librarian pipeline with full grounding. The E2E test uses simulated responses with intentional hallucinations (10% hallucinated, 20% mixed) to validate detection capabilities. The 9.5% measured rate reflects the test corpus composition.

---

## E2E Test Composition Analysis

The E2E hallucination detection test (`e2e_hallucination_detection.test.ts`) generates:
- 70% correct responses (7 of 10) - based on actual AST facts
- 20% mixed responses (2 of 10) - valid + invalid citations
- 10% hallucinated responses (1 of 10) - entirely fabricated

### Observed Results from Test Run

```
E2E HALLUCINATION RATE MEASUREMENT
========================================
Responses tested: 10
Total citations: 13
Valid citations: 9
Invalid citations: 4

Citation accuracy: 69.2%
Entailment rate: 62.1%
Contradiction rate: 0.0%

>>> HALLUCINATION RATE: 9.5% <<<
```

---

## Failure Categorization

### Category 1: Citation Verification Failures (4 citations = 30.8%)

**Pattern**: File path citations pointing to non-existent files or wrong line numbers.

| Failure Type | Count | Example |
|--------------|-------|---------|
| File not found | 2 | `src/fake/path.ts:999` |
| Line out of range | 1 | `realfile.ts:99999` |
| Mixed (valid file, wrong content) | 1 | Valid path but wrong identifier |

**Root Cause Hypothesis (H1)**: The simulated hallucinated responses intentionally reference non-existent files (`src/fake/path.ts`, `src/nonexistent/helper.ts`, `src/hallucinated.ts`). This tests the citation verifier's ability to detect fabricated paths.

**Root Cause Hypothesis (H2)**: The mixed responses combine valid AST facts with fabricated helper functions. The citation verifier correctly flags the non-existent portions.

### Category 2: Entailment Check Gaps (37.9% non-entailed)

**Pattern**: Claims that cannot be verified against AST facts.

| Issue Type | Estimated Count | Reason |
|------------|-----------------|--------|
| Neutral (no evidence) | ~3 | Behavioral claims without AST support |
| Pattern mismatch | ~2 | Claim extraction regex doesn't match phrasing |
| Cross-reference gaps | ~1 | Reference to identifier in different file |

**Root Cause Hypothesis (H3)**: The entailment checker has 40+ claim patterns (expanded in WU-1408) but still misses certain phrasings. Natural language variation creates claims that don't match regex patterns.

**Root Cause Hypothesis (H4)**: Behavioral claims (e.g., "X calls Y", "X handles Z") require call graph analysis. The AST fact extractor extracts call relationships but the entailment checker may not fully utilize them.

### Category 3: MiniCheck Grounding Gaps

**CoVe Impact Test Results**:
```
BEFORE CoVe:
- Non-entailed claims: 4
- Hallucination rate: 50.0%

AFTER CoVe:
- Non-entailed claims: 2
- Hallucination rate: 25.0%

>>> IMPROVEMENT: 25.0 percentage points <<<
```

**Root Cause Hypothesis (H5)**: MiniCheck integration (WU-1410b) uses 60/40 weighted average between entailment (0.6) and MiniCheck (0.4) scores. For claims where entailment fails but MiniCheck shows moderate grounding, the combined score may be too lenient.

**Root Cause Hypothesis (H6)**: MiniCheck grounding (77.4% reported in WU-1410) works well for term-level verification but struggles with:
- Negations ("does not have", "is not")
- Quantifiers ("takes 10 parameters" vs "takes 3 parameters")
- Temporal claims ("was deprecated", "recently added")

---

## Root Cause Hypotheses (Ranked by Likelihood)

### High Likelihood

| ID | Hypothesis | Evidence | Test Type |
|----|------------|----------|-----------|
| H1 | Non-existent file citations fail (expected) | Test corpus intentionally includes fabricated paths | Behavioral |
| H3 | Claim pattern coverage gaps | 40 patterns added but natural language varies | Code inspection |
| H4 | Behavioral claim verification weak | AST has call data but checker underutilizes | Code inspection |

### Medium Likelihood

| ID | Hypothesis | Evidence | Test Type |
|----|------------|----------|-----------|
| H5 | Entailment+MiniCheck weighting suboptimal | 60/40 split may need tuning per claim type | A/B experiment |
| H2 | Mixed responses correctly detected | Verifier properly splits valid/invalid | Behavioral |
| H6 | MiniCheck struggles with negation/quantifiers | Heuristic-based scorer limitations | Log analysis |

### Low Likelihood

| ID | Hypothesis | Evidence | Test Type |
|----|------------|----------|-----------|
| H7 | Line tolerance too narrow | Already increased to 15 lines in WU-1407 | Behavioral |
| H8 | AST fact extraction incomplete | 298 facts from typedriver-ts is comprehensive | Code inspection |

---

## Proposed Fixes (Ranked by Expected Impact)

### Fix 1: Add Dynamic Claim Pattern Expansion
**Expected Impact**: 2.0 pp reduction
**Effort**: Medium (8-12 hours)
**Description**: Implement a pattern learning system that analyzes failed claim extractions and suggests new patterns. Current 40 patterns are static; dynamic expansion based on test failures would improve coverage.

**Implementation**:
1. Log all claim extraction attempts that fail pattern matching
2. Cluster similar failed claims by structure
3. Generate candidate patterns from clusters
4. Human review + automated test validation

### Fix 2: Improve Behavioral Claim Verification
**Expected Impact**: 1.5 pp reduction
**Effort**: Medium (6-10 hours)
**Description**: Enhance entailment checker to better utilize call graph facts for behavioral claims. Currently extracts calls but doesn't fully leverage for "X calls Y" claims.

**Implementation**:
1. Add specific call graph traversal in `checkFunctionClaimSupport`
2. Build callee index for faster lookup
3. Support transitive calls (A calls B, B calls C -> A transitively calls C)

### Fix 3: Tune MiniCheck Weighting by Claim Type
**Expected Impact**: 1.0 pp reduction
**Effort**: Low (4-6 hours)
**Description**: Use different entailment/MiniCheck weights based on claim type:
- Structural claims: 70/30 (favor entailment)
- Behavioral claims: 50/50 (balanced)
- Factual claims: 60/40 (current default)

**Implementation**:
1. Add claim-type-aware weighting in `ChainOfVerification.verifyQuestion()`
2. Run A/B test to validate improvement
3. Calibrate weights based on validation results

### Fix 4: Add Negation/Quantifier Handling to MiniCheck
**Expected Impact**: 0.7 pp reduction
**Effort**: Medium (6-8 hours)
**Description**: Enhance `minicheck_scorer.ts` to handle negations ("is not", "does not") and quantifiers ("has N parameters") more accurately.

**Implementation**:
1. Detect negation tokens and invert grounding logic
2. Extract numeric quantifiers and compare against AST facts
3. Add specific scoring for "has N X" patterns

### Fix 5: Expand AST Fact Details
**Expected Impact**: 0.5 pp reduction
**Effort**: Low (3-4 hours)
**Description**: Include additional details in AST facts that support more claim types:
- Deprecation annotations (`@deprecated` comments)
- Visibility modifiers (private/public/protected)
- Generic type parameters

**Implementation**:
1. Extend `ASTFactExtractor` to capture JSDoc annotations
2. Add modifier extraction for all declarations
3. Capture type parameters for generic functions/classes

### Fix 6: Confidence Threshold Tuning
**Expected Impact**: 0.3 pp reduction
**Effort**: Very Low (1-2 hours)
**Description**: Current `minVerificationConfidence` is 0.5. Analysis suggests 0.55-0.6 may better balance precision/recall.

**Implementation**:
1. Run grid search over [0.45, 0.50, 0.55, 0.60, 0.65] thresholds
2. Evaluate on holdout test set
3. Select threshold minimizing hallucination rate while maintaining recall

---

## Expected Impact Summary

| Fix | Impact | Effort | Priority |
|-----|--------|--------|----------|
| Fix 1: Dynamic patterns | -2.0 pp | Medium | P1 |
| Fix 2: Behavioral verification | -1.5 pp | Medium | P1 |
| Fix 3: MiniCheck weighting | -1.0 pp | Low | P2 |
| Fix 4: Negation handling | -0.7 pp | Medium | P2 |
| Fix 5: AST fact details | -0.5 pp | Low | P3 |
| Fix 6: Threshold tuning | -0.3 pp | Very Low | P3 |

**Total Expected Reduction**: 6.0 pp (theoretical max, assuming no overlap)
**Realistic Expected Reduction**: 3.5-4.5 pp (accounting for overlap and diminishing returns)
**Target Gap**: 4.5 pp
**Achievable Target**: <5% hallucination rate with P1 + P2 fixes

---

## Recommended Next Steps

1. **Immediate (P1)**: Implement Fix 1 (Dynamic patterns) and Fix 2 (Behavioral verification)
   - These address the highest-impact gaps
   - Combined expected improvement: 3.5 pp

2. **Short-term (P2)**: Implement Fix 3 (MiniCheck weighting) and Fix 4 (Negation handling)
   - Fine-tune the verification stack
   - Combined expected improvement: 1.7 pp

3. **Validation**: Re-run E2E hallucination detection test after P1 fixes
   - Target: <7% hallucination rate
   - Validate hypothesis accuracy

4. **Calibration**: If target not met after P1+P2, proceed to P3 fixes and threshold tuning

5. **Documentation**: Update STATUS.md with new measured metrics after each fix wave

---

## Evidence References

- Test output: `src/evaluation/__tests__/e2e_hallucination_detection.test.ts`
- Citation verifier: `src/evaluation/citation_verifier.ts` (LINE_TOLERANCE = 15)
- Entailment checker: `src/evaluation/entailment_checker.ts` (40+ patterns)
- Chain-of-Verification: `src/evaluation/chain_of_verification.ts` (60/40 weighting)
- MiniCheck scorer: `src/evaluation/minicheck_scorer.ts` (heuristic implementation)
- AST fact extractor: `src/evaluation/ast_fact_extractor.ts` (6 fact types)
- External repo facts: `eval-corpus/external-repos/typedriver-ts` (298 facts)

---

## Appendix: Test Corpus Details

### typedriver-ts Repository Facts
- Total facts: 298
- Functions: 66
- Classes: 7
- Types: 13

### Key Files Tested
- `src/compile.ts`: 4 functions (compile, CreateTypeScriptValidator, etc.)
- `src/validator.ts`: Validator class with 7 methods (schema, check, parse, etc.)

### Simulated Response Distribution
```typescript
// 70% correct responses
for (let i = 0; i < 7; i++) {
  responses.push(generateCorrectResponse(typedriverFacts, TYPEDRIVER_REPO));
}
// 20% mixed responses (valid + invalid)
for (let i = 0; i < 2; i++) {
  responses.push(generateMixedResponse(typedriverFacts, TYPEDRIVER_REPO));
}
// 10% hallucinated response
responses.push(generateHallucinatedResponse(typedriverFacts, TYPEDRIVER_REPO));
```

This test composition intentionally includes hallucinations to validate detection capabilities. The measured 9.5% rate reflects this corpus design, not production Librarian output quality.
