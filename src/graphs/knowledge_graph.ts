/**
 * @fileoverview Code Knowledge Graph Builder and Query Engine
 *
 * Builds and queries a unified knowledge graph connecting code entities
 * through multiple relationship types: imports, calls, clones, debt,
 * authorship, co-change patterns, and semantic similarity.
 *
 * Based on 2025-2026 research:
 * - Code knowledge graphs achieve 95%+ semantic alignment
 * - Outperform vector retrieval baselines by 15-30%
 * - Enable precise impact analysis and change propagation
 * - Support fault localization and debugging assistance
 */

import { createHash } from 'crypto';
import type {
  LibrarianStorage,
  KnowledgeGraphEdge,
  KnowledgeEdgeType,
  KnowledgeSubgraph,
  KnowledgeEdgeQueryOptions,
  CloneEntry,
  DebtMetrics,
  BlameEntry,
  DiffRecord,
} from '../storage/types.js';
import type { GraphEdge, FunctionKnowledge, ModuleKnowledge, FileKnowledge } from '../types.js';
import { detectCommunities } from './communities.js';
import { computeBetweennessCentrality, computeClosenessCentrality } from './centrality.js';
import { buildTemporalGraph, type CochangeEdge } from './temporal_graph.js';

// ============================================================================
// TYPES
// ============================================================================

export interface KnowledgeGraphBuildOptions {
  workspace: string;
  storage: LibrarianStorage;
  includeImports?: boolean;      // Build from AST import edges (default: true)
  includeCalls?: boolean;        // Build from function call edges (default: true)
  includeClones?: boolean;       // Build from clone analysis (default: true)
  includeCochange?: boolean;     // Build from temporal co-change (default: true)
  includeAuthorship?: boolean;   // Build from blame data (default: true)
  includeDebt?: boolean;         // Build from debt relationships (default: true)
  includeSimilarity?: boolean;   // Build from embedding similarity (default: false - expensive)
  minEdgeWeight?: number;        // Minimum edge weight to include (default: 0.1)
  maxCommits?: number;           // For co-change analysis (default: 500)
}

export interface KnowledgeGraphBuildResult {
  edgesCreated: number;
  edgesByType: Record<KnowledgeEdgeType, number>;
  nodesDiscovered: number;
  communitiesDetected: number;
  durationMs: number;
}

export interface CloneCluster {
  clusterId: string;
  members: Array<{
    entityId: string;
    entityType: 'function' | 'module' | 'file';
    label: string;
  }>;
  avgSimilarity: number;
  cloneType: 'exact' | 'type1' | 'type2' | 'type3' | 'semantic';
  refactoringPotential: number; // 0-1
}

export interface DebtHotspotResult {
  entityId: string;
  entityType: string;
  totalDebt: number;
  connectedDebt: number;      // Debt in connected nodes
  debtContagion: number;      // How much debt could spread
  centralityScore: number;
  recommendations: string[];
}

export interface OwnershipMapResult {
  entities: Array<{
    entityId: string;
    entityType: string;
    primaryAuthor: string;
    ownership: number;           // 0-1 percentage
    contributors: Array<{ author: string; percentage: number }>;
  }>;
  authorSummary: Record<string, {
    totalEntities: number;
    totalLines: number;
    primaryOwner: string[];
  }>;
}

export interface ImpactAnalysisResult {
  targetId: string;
  directImpact: Array<{
    entityId: string;
    entityType: string;
    relationship: KnowledgeEdgeType;
    impactScore: number;
  }>;
  transitiveImpact: Array<{
    entityId: string;
    entityType: string;
    pathLength: number;
    impactScore: number;
  }>;
  riskScore: number;           // 0-1 overall change risk
  recommendations: string[];
}

export interface EvolutionTimelineResult {
  entityId: string;
  timeline: Array<{
    date: string;
    event: 'created' | 'modified' | 'refactored' | 'cloned' | 'debt_introduced' | 'debt_resolved';
    description: string;
    relatedEntities: string[];
  }>;
  stability: number;           // 0-1
  churnRate: number;
}

// ============================================================================
// EDGE ID GENERATION
// ============================================================================

function generateEdgeId(sourceId: string, targetId: string, edgeType: KnowledgeEdgeType): string {
  return createHash('sha256')
    .update(`${sourceId}:${targetId}:${edgeType}`)
    .digest('hex')
    .slice(0, 32);
}

// ============================================================================
// GRAPH BUILDING
// ============================================================================

/**
 * Build knowledge edges from existing AST graph edges (imports, calls, extends).
 */
async function buildFromGraphEdges(
  storage: LibrarianStorage,
  includeImports: boolean,
  includeCalls: boolean
): Promise<KnowledgeGraphEdge[]> {
  const edges: KnowledgeGraphEdge[] = [];
  const now = new Date().toISOString();

  // Get existing graph edges from storage
  const graphEdges = await storage.getGraphEdges({});

  for (const edge of graphEdges) {
    // Map graph edge type to knowledge edge type
    let knowledgeEdgeType: KnowledgeEdgeType | null = null;
    if (edge.edgeType === 'imports' && includeImports) {
      knowledgeEdgeType = 'imports';
    } else if (edge.edgeType === 'calls' && includeCalls) {
      knowledgeEdgeType = 'calls';
    } else if (edge.edgeType === 'extends') {
      knowledgeEdgeType = 'extends';
    } else if (edge.edgeType === 'implements') {
      knowledgeEdgeType = 'implements';
    }

    if (!knowledgeEdgeType) continue;

    edges.push({
      id: generateEdgeId(edge.fromId, edge.toId, knowledgeEdgeType),
      sourceId: edge.fromId,
      targetId: edge.toId,
      sourceType: mapEntityType(edge.fromType),
      targetType: mapEntityType(edge.toType),
      edgeType: knowledgeEdgeType,
      weight: edge.confidence ?? 1.0,
      confidence: 1.0, // AST-derived edges have high confidence
      metadata: {},
      computedAt: now,
    });
  }

  return edges;
}

/**
 * Build knowledge edges from clone analysis results.
 */
async function buildFromClones(storage: LibrarianStorage): Promise<KnowledgeGraphEdge[]> {
  const edges: KnowledgeGraphEdge[] = [];
  const now = new Date().toISOString();

  const clones = await storage.getCloneEntries({ limit: 10000 });

  for (const clone of clones) {
    edges.push({
      id: generateEdgeId(clone.entityId1, clone.entityId2, 'clone_of'),
      sourceId: clone.entityId1,
      targetId: clone.entityId2,
      sourceType: clone.entityType as KnowledgeGraphEdge['sourceType'],
      targetType: clone.entityType as KnowledgeGraphEdge['targetType'],
      edgeType: 'clone_of',
      weight: clone.similarity,
      confidence: 0.85, // Clone detection has inherent uncertainty
      metadata: {
        cloneType: clone.cloneType,
        cloneGroupId: clone.cloneGroupId,
      },
      computedAt: now,
    });
  }

  return edges;
}

/**
 * Build knowledge edges from temporal co-change patterns.
 */
async function buildFromCochange(
  workspace: string,
  storage: LibrarianStorage,
  maxCommits: number
): Promise<KnowledgeGraphEdge[]> {
  const edges: KnowledgeGraphEdge[] = [];
  const now = new Date().toISOString();

  const temporal = buildTemporalGraph(workspace, { maxCommits });

  for (const cochange of temporal.edges) {
    // Only include significant co-change relationships
    if (cochange.strength < 0.1 || cochange.changeCount < 2) continue;

    edges.push({
      id: generateEdgeId(cochange.fileA, cochange.fileB, 'co_changed'),
      sourceId: cochange.fileA,
      targetId: cochange.fileB,
      sourceType: 'file',
      targetType: 'file',
      edgeType: 'co_changed',
      weight: cochange.strength,
      confidence: Math.min(1.0, cochange.changeCount / 10), // More co-changes = more confidence
      metadata: {
        changeCount: cochange.changeCount,
        totalChanges: cochange.totalChanges,
      },
      computedAt: now,
    });
  }

  return edges;
}

/**
 * Build knowledge edges from blame/authorship data.
 */
async function buildFromAuthorship(storage: LibrarianStorage): Promise<KnowledgeGraphEdge[]> {
  const edges: KnowledgeGraphEdge[] = [];
  const now = new Date().toISOString();

  // Get all blame entries and aggregate by file+author
  const blameEntries = await storage.getBlameEntries({ limit: 50000 });

  // Group by file and calculate author ownership
  const fileAuthorship = new Map<string, Map<string, number>>();
  const fileLineCount = new Map<string, number>();

  for (const entry of blameEntries) {
    const lines = entry.lineEnd - entry.lineStart + 1;

    if (!fileAuthorship.has(entry.filePath)) {
      fileAuthorship.set(entry.filePath, new Map());
      fileLineCount.set(entry.filePath, 0);
    }

    const authorMap = fileAuthorship.get(entry.filePath)!;
    authorMap.set(entry.author, (authorMap.get(entry.author) || 0) + lines);
    fileLineCount.set(entry.filePath, (fileLineCount.get(entry.filePath) || 0) + lines);
  }

  // Create authorship edges
  for (const [filePath, authors] of fileAuthorship) {
    const totalLines = fileLineCount.get(filePath) || 1;

    for (const [author, lines] of authors) {
      const ownership = lines / totalLines;
      if (ownership < 0.05) continue; // Skip trivial contributions

      edges.push({
        id: generateEdgeId(filePath, author, 'authored_by'),
        sourceId: filePath,
        targetId: author,
        sourceType: 'file',
        targetType: 'author',
        edgeType: 'authored_by',
        weight: ownership,
        confidence: 0.95, // Git blame is very reliable
        metadata: {
          linesOwned: lines,
          totalLines,
        },
        computedAt: now,
      });
    }
  }

  return edges;
}

/**
 * Build knowledge edges from debt analysis results.
 */
async function buildFromDebt(storage: LibrarianStorage): Promise<KnowledgeGraphEdge[]> {
  const edges: KnowledgeGraphEdge[] = [];
  const now = new Date().toISOString();

  const debtMetrics = await storage.getDebtMetrics({ limit: 10000 });

  // Find entities with similar debt profiles (debt_related)
  const highDebtEntities = debtMetrics.filter(d => d.totalDebt > 50);

  for (let i = 0; i < highDebtEntities.length; i++) {
    for (let j = i + 1; j < highDebtEntities.length; j++) {
      const a = highDebtEntities[i];
      const b = highDebtEntities[j];

      // Calculate debt profile similarity
      const similarity = calculateDebtProfileSimilarity(a, b);
      if (similarity < 0.6) continue;

      edges.push({
        id: generateEdgeId(a.entityId, b.entityId, 'debt_related'),
        sourceId: a.entityId,
        targetId: b.entityId,
        sourceType: a.entityType as KnowledgeGraphEdge['sourceType'],
        targetType: b.entityType as KnowledgeGraphEdge['targetType'],
        edgeType: 'debt_related',
        weight: similarity,
        confidence: 0.7,
        metadata: {
          aDebt: a.totalDebt,
          bDebt: b.totalDebt,
          sharedCategories: findSharedDebtCategories(a, b),
        },
        computedAt: now,
      });
    }
  }

  return edges;
}

/**
 * Build hierarchical containment edges (part_of).
 */
async function buildHierarchicalEdges(storage: LibrarianStorage): Promise<KnowledgeGraphEdge[]> {
  const edges: KnowledgeGraphEdge[] = [];
  const now = new Date().toISOString();

  // Functions are part of files
  const functions = await storage.getFunctions({ limit: 50000 });
  for (const fn of functions) {
    edges.push({
      id: generateEdgeId(fn.id, fn.filePath, 'part_of'),
      sourceId: fn.id,
      targetId: fn.filePath,
      sourceType: 'function',
      targetType: 'file',
      edgeType: 'part_of',
      weight: 1.0,
      confidence: 1.0,
      metadata: {},
      computedAt: now,
    });
  }

  // Files are part of directories
  const files = await storage.getFiles({ limit: 50000 });
  for (const file of files) {
    const dirPath = file.path.split('/').slice(0, -1).join('/') || '.';
    edges.push({
      id: generateEdgeId(file.path, dirPath, 'part_of'),
      sourceId: file.path,
      targetId: dirPath,
      sourceType: 'file',
      targetType: 'directory',
      edgeType: 'part_of',
      weight: 1.0,
      confidence: 1.0,
      metadata: {},
      computedAt: now,
    });
  }

  return edges;
}

// ============================================================================
// HELPER FUNCTIONS
// ============================================================================

function mapEntityType(type: string): KnowledgeGraphEdge['sourceType'] {
  const typeMap: Record<string, KnowledgeGraphEdge['sourceType']> = {
    function: 'function',
    module: 'module',
    file: 'file',
    directory: 'directory',
    class: 'module',
    interface: 'module',
  };
  return typeMap[type] || 'file';
}

function calculateDebtProfileSimilarity(a: DebtMetrics, b: DebtMetrics): number {
  const categories = [
    'complexityDebt',
    'duplicationDebt',
    'couplingDebt',
    'coverageDebt',
    'architectureDebt',
    'churnDebt',
  ] as const;

  let sumProduct = 0;
  let sumA2 = 0;
  let sumB2 = 0;

  for (const cat of categories) {
    const aVal = a[cat] ?? 0;
    const bVal = b[cat] ?? 0;
    sumProduct += aVal * bVal;
    sumA2 += aVal * aVal;
    sumB2 += bVal * bVal;
  }

  const denominator = Math.sqrt(sumA2) * Math.sqrt(sumB2);
  return denominator > 0 ? sumProduct / denominator : 0;
}

function findSharedDebtCategories(a: DebtMetrics, b: DebtMetrics): string[] {
  const categories = [
    { key: 'complexityDebt', name: 'complexity' },
    { key: 'duplicationDebt', name: 'duplication' },
    { key: 'couplingDebt', name: 'coupling' },
    { key: 'coverageDebt', name: 'coverage' },
    { key: 'architectureDebt', name: 'architecture' },
    { key: 'churnDebt', name: 'churn' },
  ] as const;

  const shared: string[] = [];
  for (const cat of categories) {
    const aVal = a[cat.key] ?? 0;
    const bVal = b[cat.key] ?? 0;
    if (aVal > 30 && bVal > 30) {
      shared.push(cat.name);
    }
  }
  return shared;
}

// ============================================================================
// MAIN BUILD FUNCTION
// ============================================================================

/**
 * Build the knowledge graph from all available sources.
 */
export async function buildKnowledgeGraph(
  options: KnowledgeGraphBuildOptions
): Promise<KnowledgeGraphBuildResult> {
  const startTime = Date.now();
  const {
    workspace,
    storage,
    includeImports = true,
    includeCalls = true,
    includeClones = true,
    includeCochange = true,
    includeAuthorship = true,
    includeDebt = true,
    minEdgeWeight = 0.1,
    maxCommits = 500,
  } = options;

  const allEdges: KnowledgeGraphEdge[] = [];
  const edgesByType: Record<KnowledgeEdgeType, number> = {
    imports: 0,
    calls: 0,
    extends: 0,
    implements: 0,
    clone_of: 0,
    debt_related: 0,
    authored_by: 0,
    reviewed_by: 0,
    evolved_from: 0,
    co_changed: 0,
    tests: 0,
    documents: 0,
    depends_on: 0,
    similar_to: 0,
    part_of: 0,
  };

  // Build from graph edges (imports, calls, extends, implements)
  if (includeImports || includeCalls) {
    const graphEdges = await buildFromGraphEdges(storage, includeImports, includeCalls);
    allEdges.push(...graphEdges);
  }

  // Build from clone analysis
  if (includeClones) {
    const cloneEdges = await buildFromClones(storage);
    allEdges.push(...cloneEdges);
  }

  // Build from co-change patterns
  if (includeCochange) {
    const cochangeEdges = await buildFromCochange(workspace, storage, maxCommits);
    allEdges.push(...cochangeEdges);
  }

  // Build from authorship
  if (includeAuthorship) {
    const authorshipEdges = await buildFromAuthorship(storage);
    allEdges.push(...authorshipEdges);
  }

  // Build from debt
  if (includeDebt) {
    const debtEdges = await buildFromDebt(storage);
    allEdges.push(...debtEdges);
  }

  // Build hierarchical edges
  const hierarchicalEdges = await buildHierarchicalEdges(storage);
  allEdges.push(...hierarchicalEdges);

  // Filter by minimum weight
  const filteredEdges = allEdges.filter(e => e.weight >= minEdgeWeight);

  // Count by type
  for (const edge of filteredEdges) {
    edgesByType[edge.edgeType]++;
  }

  // Store edges
  await storage.upsertKnowledgeEdges(filteredEdges);

  // Detect communities for later queries
  const graph = buildGraphFromEdges(filteredEdges);
  const communities = detectCommunities(graph);
  const uniqueCommunities = new Set(communities.values()).size;

  return {
    edgesCreated: filteredEdges.length,
    edgesByType,
    nodesDiscovered: graph.size,
    communitiesDetected: uniqueCommunities,
    durationMs: Date.now() - startTime,
  };
}

/**
 * Convert knowledge edges to a graph structure for algorithms.
 */
function buildGraphFromEdges(edges: KnowledgeGraphEdge[]): Map<string, Set<string>> {
  const graph = new Map<string, Set<string>>();

  for (const edge of edges) {
    if (!graph.has(edge.sourceId)) {
      graph.set(edge.sourceId, new Set());
    }
    if (!graph.has(edge.targetId)) {
      graph.set(edge.targetId, new Set());
    }
    graph.get(edge.sourceId)!.add(edge.targetId);
  }

  return graph;
}

// ============================================================================
// CLONE CLUSTER QUERIES
// ============================================================================

/**
 * Find clusters of cloned code.
 */
export async function getCloneClusters(
  storage: LibrarianStorage,
  options?: { minClusterSize?: number; minSimilarity?: number }
): Promise<CloneCluster[]> {
  const { minClusterSize = 2, minSimilarity = 0.7 } = options || {};

  const cloneEdges = await storage.getKnowledgeEdges({
    edgeType: 'clone_of',
    minWeight: minSimilarity,
    limit: 10000,
  });

  // Build clone graph and detect communities
  const cloneGraph = buildGraphFromEdges(cloneEdges);
  const communities = detectCommunities(cloneGraph);

  // Group by community
  const clusterMap = new Map<number, Array<{ id: string; type: string }>>();
  for (const [nodeId, clusterId] of communities) {
    if (!clusterMap.has(clusterId)) {
      clusterMap.set(clusterId, []);
    }
    // Find the edge to get entity type
    const edge = cloneEdges.find(e => e.sourceId === nodeId || e.targetId === nodeId);
    const type = edge?.sourceId === nodeId ? edge.sourceType : edge?.targetType || 'function';
    clusterMap.get(clusterId)!.push({ id: nodeId, type });
  }

  // Build clusters
  const clusters: CloneCluster[] = [];
  for (const [clusterId, members] of clusterMap) {
    if (members.length < minClusterSize) continue;

    // Calculate average similarity within cluster
    let totalSimilarity = 0;
    let count = 0;
    for (const edge of cloneEdges) {
      const sourceInCluster = members.some(m => m.id === edge.sourceId);
      const targetInCluster = members.some(m => m.id === edge.targetId);
      if (sourceInCluster && targetInCluster) {
        totalSimilarity += edge.weight;
        count++;
      }
    }

    // Determine clone type from edges
    const cloneTypes = cloneEdges
      .filter(e => members.some(m => m.id === e.sourceId))
      .map(e => e.metadata.cloneType as string)
      .filter(Boolean);
    const dominantType = findDominantCloneType(cloneTypes);

    clusters.push({
      clusterId: `cluster-${clusterId}`,
      members: members.map(m => ({
        entityId: m.id,
        entityType: m.type as 'function' | 'module' | 'file',
        label: m.id.split('/').pop() || m.id,
      })),
      avgSimilarity: count > 0 ? totalSimilarity / count : 0,
      cloneType: dominantType,
      refactoringPotential: calculateRefactoringPotential(members.length, count > 0 ? totalSimilarity / count : 0, dominantType),
    });
  }

  return clusters.sort((a, b) => b.refactoringPotential - a.refactoringPotential);
}

function findDominantCloneType(types: string[]): CloneCluster['cloneType'] {
  const counts: Record<string, number> = {};
  for (const t of types) {
    counts[t] = (counts[t] || 0) + 1;
  }
  let dominant = 'type2';
  let maxCount = 0;
  for (const [type, count] of Object.entries(counts)) {
    if (count > maxCount) {
      maxCount = count;
      dominant = type;
    }
  }
  return dominant as CloneCluster['cloneType'];
}

function calculateRefactoringPotential(
  clusterSize: number,
  avgSimilarity: number,
  cloneType: CloneCluster['cloneType']
): number {
  // Exact clones have highest potential
  const typeMultiplier: Record<string, number> = {
    exact: 1.0,
    type1: 0.95,
    type2: 0.8,
    type3: 0.6,
    semantic: 0.4,
  };

  const sizeScore = Math.min(1.0, clusterSize / 5); // Larger clusters = more value
  const similarityScore = avgSimilarity;
  const typeScore = typeMultiplier[cloneType] || 0.5;

  return (sizeScore * 0.3 + similarityScore * 0.4 + typeScore * 0.3);
}

// ============================================================================
// DEBT HOTSPOT QUERIES
// ============================================================================

/**
 * Find debt hotspots - high-debt nodes with high centrality.
 */
export async function getDebtHotspots(
  storage: LibrarianStorage,
  options?: { minDebt?: number; limit?: number }
): Promise<DebtHotspotResult[]> {
  const { minDebt = 30, limit = 20 } = options || {};

  // Get all edges for centrality calculation
  const edges = await storage.getKnowledgeEdges({ limit: 50000 });
  const graph = buildGraphFromEdges(edges);

  // Calculate centrality
  const betweenness = computeBetweennessCentrality(graph);
  const closeness = computeClosenessCentrality(graph);

  // Get debt metrics
  const debtMetrics = await storage.getDebtMetrics({ limit: 10000 });
  const debtMap = new Map(debtMetrics.map(d => [d.entityId, d]));

  // Calculate connected debt
  const connectedDebt = new Map<string, number>();
  for (const [nodeId, neighbors] of graph) {
    let totalConnectedDebt = 0;
    for (const neighbor of neighbors) {
      const neighborDebt = debtMap.get(neighbor);
      if (neighborDebt) {
        totalConnectedDebt += neighborDebt.totalDebt;
      }
    }
    connectedDebt.set(nodeId, totalConnectedDebt);
  }

  // Build hotspot results
  const hotspots: DebtHotspotResult[] = [];
  for (const debt of debtMetrics) {
    if (debt.totalDebt < minDebt) continue;

    const centrality = (betweenness.get(debt.entityId) || 0) * 0.5 +
                       (closeness.get(debt.entityId) || 0) * 0.5;

    const connected = connectedDebt.get(debt.entityId) || 0;
    const neighborCount = graph.get(debt.entityId)?.size || 0;
    const debtContagion = neighborCount > 0 ? (debt.totalDebt / 100) * (connected / (neighborCount * 100)) : 0;

    hotspots.push({
      entityId: debt.entityId,
      entityType: debt.entityType,
      totalDebt: debt.totalDebt,
      connectedDebt: connected,
      debtContagion: Math.min(1.0, debtContagion),
      centralityScore: centrality,
      recommendations: generateDebtRecommendations(debt, centrality, connected),
    });
  }

  return hotspots
    .sort((a, b) => (b.totalDebt * b.centralityScore) - (a.totalDebt * a.centralityScore))
    .slice(0, limit);
}

function generateDebtRecommendations(
  debt: DebtMetrics,
  centrality: number,
  connectedDebt: number
): string[] {
  const recommendations: string[] = [];

  if (debt.complexityDebt && debt.complexityDebt > 50) {
    recommendations.push('Consider breaking down into smaller functions');
  }
  if (debt.duplicationDebt && debt.duplicationDebt > 50) {
    recommendations.push('Extract common code to shared utility');
  }
  if (debt.couplingDebt && debt.couplingDebt > 50) {
    recommendations.push('Introduce interface to reduce direct coupling');
  }
  if (centrality > 0.5) {
    recommendations.push('High centrality - changes here affect many modules');
  }
  if (connectedDebt > 200) {
    recommendations.push('Connected to high-debt code - consider broader refactoring');
  }

  return recommendations;
}

// ============================================================================
// OWNERSHIP MAP QUERIES
// ============================================================================

/**
 * Get ownership map for the codebase.
 */
export async function getOwnershipMap(
  storage: LibrarianStorage,
  options?: { path?: string; minOwnership?: number }
): Promise<OwnershipMapResult> {
  const { minOwnership = 0.1 } = options || {};

  const authorshipEdges = await storage.getKnowledgeEdges({
    edgeType: 'authored_by',
    limit: 50000,
  });

  // Group by entity
  const entityOwnership = new Map<string, Array<{ author: string; weight: number; type: string }>>();
  for (const edge of authorshipEdges) {
    if (!entityOwnership.has(edge.sourceId)) {
      entityOwnership.set(edge.sourceId, []);
    }
    entityOwnership.get(edge.sourceId)!.push({
      author: edge.targetId,
      weight: edge.weight,
      type: edge.sourceType,
    });
  }

  // Build entity results
  const entities: OwnershipMapResult['entities'] = [];
  for (const [entityId, authors] of entityOwnership) {
    const sorted = authors.sort((a, b) => b.weight - a.weight);
    const primary = sorted[0];
    if (!primary) continue;

    entities.push({
      entityId,
      entityType: primary.type,
      primaryAuthor: primary.author,
      ownership: primary.weight,
      contributors: sorted
        .filter(a => a.weight >= minOwnership)
        .map(a => ({ author: a.author, percentage: a.weight })),
    });
  }

  // Build author summary
  const authorSummary: OwnershipMapResult['authorSummary'] = {};
  for (const entity of entities) {
    for (const contrib of entity.contributors) {
      if (!authorSummary[contrib.author]) {
        authorSummary[contrib.author] = {
          totalEntities: 0,
          totalLines: 0,
          primaryOwner: [],
        };
      }
      authorSummary[contrib.author].totalEntities++;
      if (entity.primaryAuthor === contrib.author) {
        authorSummary[contrib.author].primaryOwner.push(entity.entityId);
      }
    }
  }

  return { entities, authorSummary };
}

// ============================================================================
// IMPACT ANALYSIS
// ============================================================================

/**
 * Analyze the impact of changing a specific entity.
 */
export async function analyzeImpact(
  storage: LibrarianStorage,
  targetId: string,
  options?: { maxDepth?: number }
): Promise<ImpactAnalysisResult> {
  const { maxDepth = 3 } = options || {};

  // Get edges FROM this entity (what depends on it)
  const directEdges = await storage.getKnowledgeEdgesFrom(targetId);

  // Also get edges TO this entity (what it depends on)
  const reverseDeps = await storage.getKnowledgeEdgesTo(targetId);

  // Build direct impact
  const directImpact: ImpactAnalysisResult['directImpact'] = directEdges.map(edge => ({
    entityId: edge.targetId,
    entityType: edge.targetType,
    relationship: edge.edgeType,
    impactScore: calculateDirectImpact(edge),
  }));

  // BFS for transitive impact
  const visited = new Set<string>([targetId]);
  const transitiveImpact: ImpactAnalysisResult['transitiveImpact'] = [];
  const queue: Array<{ id: string; depth: number }> = directEdges.map(e => ({ id: e.targetId, depth: 1 }));

  while (queue.length > 0) {
    const { id, depth } = queue.shift()!;
    if (visited.has(id) || depth > maxDepth) continue;
    visited.add(id);

    const edges = await storage.getKnowledgeEdgesFrom(id);
    const firstEdge = edges[0];

    transitiveImpact.push({
      entityId: id,
      entityType: firstEdge?.targetType || 'function',
      pathLength: depth,
      impactScore: Math.pow(0.7, depth), // Decay with distance
    });

    for (const edge of edges) {
      if (!visited.has(edge.targetId)) {
        queue.push({ id: edge.targetId, depth: depth + 1 });
      }
    }
  }

  // Calculate overall risk score
  const directRisk = directImpact.reduce((sum, i) => sum + i.impactScore, 0) / Math.max(directImpact.length, 1);
  const transitiveRisk = transitiveImpact.reduce((sum, i) => sum + i.impactScore, 0) / Math.max(transitiveImpact.length, 1);
  const riskScore = Math.min(1.0, directRisk * 0.6 + transitiveRisk * 0.4);

  // Generate recommendations
  const recommendations: string[] = [];
  if (directImpact.length > 10) {
    recommendations.push('High fan-out - consider incremental rollout');
  }
  if (transitiveImpact.length > 50) {
    recommendations.push('Large transitive impact - extensive testing recommended');
  }
  if (riskScore > 0.7) {
    recommendations.push('High-risk change - consider feature flag');
  }
  if (reverseDeps.length > 0) {
    recommendations.push(`This entity depends on ${reverseDeps.length} other entities`);
  }

  return {
    targetId,
    directImpact: directImpact.sort((a, b) => b.impactScore - a.impactScore),
    transitiveImpact: transitiveImpact.sort((a, b) => b.impactScore - a.impactScore),
    riskScore,
    recommendations,
  };
}

function calculateDirectImpact(edge: KnowledgeGraphEdge): number {
  const typeWeights: Record<KnowledgeEdgeType, number> = {
    imports: 0.9,
    calls: 0.85,
    extends: 0.95,
    implements: 0.9,
    clone_of: 0.3,
    debt_related: 0.2,
    authored_by: 0.1,
    reviewed_by: 0.05,
    evolved_from: 0.4,
    co_changed: 0.6,
    tests: 0.5,
    documents: 0.1,
    depends_on: 0.8,
    similar_to: 0.2,
    part_of: 0.7,
  };

  return (typeWeights[edge.edgeType] || 0.5) * edge.weight * edge.confidence;
}

// ============================================================================
// EVOLUTION TIMELINE
// ============================================================================

/**
 * Get the evolution timeline for an entity.
 */
export async function getEvolutionTimeline(
  storage: LibrarianStorage,
  entityId: string
): Promise<EvolutionTimelineResult> {
  const timeline: EvolutionTimelineResult['timeline'] = [];

  // Get blame data for creation/modification events
  const blameEntries = await storage.getBlameEntries({
    filePath: entityId, // Might be file path
    limit: 1000,
  });

  // Get diff records for the file
  const diffRecords = await storage.getDiffRecords({
    filePath: entityId,
    limit: 500,
  });

  // Get clone relationships
  const cloneEdges = await storage.getKnowledgeEdges({
    sourceId: entityId,
    edgeType: 'clone_of',
  });

  // Get debt history (if available)
  const debtMetrics = await storage.getDebtMetrics({
    entityId,
    limit: 1,
  });

  // Build timeline from blame data (oldest commits first)
  const commitDates = new Map<string, { date: string; author: string; summary?: string }>();
  for (const entry of blameEntries) {
    if (!commitDates.has(entry.commitHash)) {
      commitDates.set(entry.commitHash, {
        date: entry.commitDate,
        author: entry.author,
      });
    }
  }

  // Add diff records to timeline
  for (const diff of diffRecords) {
    timeline.push({
      date: diff.indexedAt,
      event: diff.changeCategory === 'structural' ? 'refactored' : 'modified',
      description: `${diff.additions} additions, ${diff.deletions} deletions (${diff.changeCategory})`,
      relatedEntities: [],
    });
  }

  // Add clone creation events
  for (const clone of cloneEdges) {
    timeline.push({
      date: clone.computedAt,
      event: 'cloned',
      description: `Clone relationship detected with ${clone.targetId}`,
      relatedEntities: [clone.targetId],
    });
  }

  // Add debt events
  if (debtMetrics.length > 0) {
    const debt = debtMetrics[0];
    if (debt.totalDebt > 50) {
      timeline.push({
        date: debt.computedAt,
        event: 'debt_introduced',
        description: `Technical debt score: ${debt.totalDebt.toFixed(1)}`,
        relatedEntities: [],
      });
    }
  }

  // Sort timeline by date
  timeline.sort((a, b) => new Date(a.date).getTime() - new Date(b.date).getTime());

  // Calculate stability (inverse of change frequency)
  const now = Date.now();
  const thirtyDaysAgo = now - 30 * 24 * 60 * 60 * 1000;
  const recentChanges = diffRecords.filter(d => new Date(d.indexedAt).getTime() > thirtyDaysAgo);
  const churnRate = recentChanges.length / 30; // Changes per day

  return {
    entityId,
    timeline,
    stability: Math.max(0, 1 - Math.min(1, churnRate * 10)),
    churnRate,
  };
}

// ============================================================================
// SUBGRAPH EXTRACTION
// ============================================================================

/**
 * Extract a focused subgraph around a root node.
 */
export async function extractSubgraph(
  storage: LibrarianStorage,
  rootId: string,
  depth: number,
  edgeTypes?: KnowledgeEdgeType[]
): Promise<KnowledgeSubgraph> {
  return storage.getKnowledgeSubgraph(rootId, depth, edgeTypes);
}

// ============================================================================
// INGESTION SOURCE
// ============================================================================

export interface KnowledgeGraphIngestionSource {
  id: string;
  name: string;
  version: string;
  priority: number;
  probe(context: { workspace: string; storage: LibrarianStorage }): Promise<boolean>;
  ingest(context: { workspace: string; storage: LibrarianStorage }): Promise<{
    items: Array<{ id: string; type: string; data: unknown }>;
    errors: string[];
    durationMs: number;
  }>;
}

/**
 * Create an ingestion source for knowledge graph building.
 */
export function createKnowledgeGraphIngestionSource(): KnowledgeGraphIngestionSource {
  return {
    id: 'knowledge-graph',
    name: 'Knowledge Graph Builder',
    version: '1.0.0',
    priority: 90, // Run after all other indexers

    async probe(context): Promise<boolean> {
      // Always available if storage is initialized
      return context.storage.isInitialized();
    },

    async ingest(context): Promise<{
      items: Array<{ id: string; type: string; data: unknown }>;
      errors: string[];
      durationMs: number;
    }> {
      const startTime = Date.now();
      const errors: string[] = [];

      try {
        const result = await buildKnowledgeGraph({
          workspace: context.workspace,
          storage: context.storage,
        });

        return {
          items: [{
            id: 'knowledge-graph-result',
            type: 'knowledge-graph',
            data: {
              edgesCreated: result.edgesCreated,
              edgesByType: result.edgesByType,
              nodesDiscovered: result.nodesDiscovered,
              communitiesDetected: result.communitiesDetected,
            },
          }],
          errors,
          durationMs: Date.now() - startTime,
        };
      } catch (error) {
        errors.push(`Knowledge graph build failed: ${error instanceof Error ? error.message : String(error)}`);
        return {
          items: [],
          errors,
          durationMs: Date.now() - startTime,
        };
      }
    },
  };
}
